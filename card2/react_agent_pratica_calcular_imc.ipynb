{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Responsável por calulcar o IMC através de interação com agente e gerar uma dica de saúde com base no IMC\n",
    "solução desenvolvida com base em https://www.youtube.com/watch?v=hKVhRA9kfeM\n",
    "\n",
    "\n",
    "A ideia é cria um agente que solicite ao usuário o peso e a altura, em kilos e em metros repectivamente.\n",
    "Após isso, o agente irá processar através das ferramentas criadas, o índice de massa corpórea do usuário, classificá-la conforme a tabela de IMC e finalmente responder ao usuário sobre sua situação e também prover uma dica de saúde com base no IMC calculado.\n",
    "desenvolvido por Paulo Victor em 07/03/2025"
   ],
   "id": "68d514750bde5e91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importação de bibliotecas",
   "id": "e4e452f0d0d97bae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:18:30.637351Z",
     "start_time": "2025-03-10T18:18:30.309506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# importando bibliotecas necessárias\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "import re\n",
    "\n",
    "# carregando arquivo de variáveis de ambiente com chave da api\n",
    "load_dotenv()\n",
    "print(\"importação funcionou\")"
   ],
   "id": "8d2d749e5bf71f73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importação funcionou\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Classes necessárias para o agente",
   "id": "bf1165f8f24cb81c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:18:34.294254Z",
     "start_time": "2025-03-10T18:18:32.687708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# instanciando a ferramenta de serviço groq para utilização do modelo LLM llama-3.3\n",
    "# testando o modelo\n",
    "\n",
    "cliente = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = cliente.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explique em 10 palavras o que é IMC\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "# modelo de agente desenvolvido por https://www.youtube.com/watch?v=hKVhRA9kfeM\n",
    "# aqui é o modelo de agente responsável por executar a cadeia de pensamentos e interações entre o usuário e também entre o agente\n",
    "class Agente:\n",
    "    def __init__(self, cliente: Groq, prompt_inicial: str = \"\") -> None:\n",
    "        self.cliente = cliente\n",
    "        self.prompt_inicial = prompt_inicial\n",
    "        self.mensagens: list = []\n",
    "        if self.prompt_inicial:\n",
    "            self.mensagens.append({\"role\": \"system\", \"content\": prompt_inicial})\n",
    "\n",
    "    def __call__(self, mensagem=\"\"):\n",
    "        if mensagem:\n",
    "            self.mensagens.append({\"role\": \"user\", \"content\": mensagem})\n",
    "        resultado = self.execute()\n",
    "        self.mensagens.append({\"role\": \"assistant\", \"content\": resultado})\n",
    "        return resultado\n",
    "\n",
    "    def execute(self):\n",
    "        completion = cliente.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.mensagens\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "# aqui é o prompt inicial, ou prompt do sistema\n",
    "prompt_inicial = \"\"\"\n",
    "Você executará uma sequência de estados começando por <Pensamento>, <Ação>, <Pausa> e <Observação>.\n",
    "No final da sequência a sua saída será uma <Resposta> e uma <Dica> de saúde.\n",
    "Use o estado <Pensamento> para descrever seu raciocínio sobre uma pergunta.\n",
    "Use <Ação> para executar um das tarefas disponíveis para você e então retorne <Pausa>.\n",
    "A <Observação> será o resultado de uma execução das tarefas.\n",
    "\n",
    "As ações disponivéis são:\n",
    "\n",
    "calcular_imc:\n",
    "exemplo, calcular_imc: (peso, altura)\n",
    "Execute o cálculo e retorne o número do IMC - a linguagem utilizada será python com pontos flutuantes\n",
    "\n",
    "\n",
    "classificacao_imc:\n",
    "exemplo, classificacao_imc: 18,5\n",
    "retorne a classificacao do IMC\n",
    "\n",
    "Sessão de exemplo:\n",
    "Pergunta: Qual o meu IMC?\n",
    "Pensamento: qual seu peso e altura?\n",
    "Ação: calcular_imc: 85, 1.70\n",
    "Pausa\n",
    "\n",
    "Uma nova interação será realizada assim:\n",
    "\n",
    "Observação: 29.41\n",
    "\n",
    "Pensamento: Preciso classificar o  IMC\n",
    "Ação: classificacao_imc: 29.41\n",
    "Pausa\n",
    "\n",
    "Uma nova interação será realizada assim:\n",
    "\n",
    "Observação: SOBREPESO\n",
    "\n",
    "Se você tem a resposta, retorne ela como <Resposta>.\n",
    "\n",
    "<Resposta>: O IMC do seu peso e altura está classificado como Sobrepeso, faça dieta e exercícios!\n",
    "\n",
    "Agora é sua vez:\n",
    "\"\"\".strip()\n",
    "\n",
    "# ferramenta utilizada para calcular o IMC com base nos dados fornecidos pelo usuário\n",
    "def calcular_imc(args) -> float:\n",
    "    '''\n",
    "    responsavel por calcular o IMC do seu peso e altura através da fórmula peso / altura * altura\n",
    "    :param args:\n",
    "    :return:\n",
    "    '''\n",
    "    args = args.split(\",\")\n",
    "    peso = float(args[0])\n",
    "    altura = float(args[1])\n",
    "    retorno = peso / (altura * altura)\n",
    "    return retorno\n",
    "\n",
    "# ferramenta utilizada para classificar o IMC\n",
    "def classificacao_imc(imc: str) -> str:\n",
    "    '''\n",
    "    responsável por classificar o IMC do seu peso e altura com base na tabela de IMC\n",
    "    :param imc:\n",
    "    :return:\n",
    "    '''\n",
    "    imc = float(imc)\n",
    "    if imc < 18.5:\n",
    "        return \"MAGREZA\"\n",
    "    if imc >= 18.5 and imc <= 24.9:\n",
    "        return \"NORMAL\"\n",
    "    if imc >= 25 and imc <= 29.9:\n",
    "        return \"SOBREPESO\"\n",
    "    if imc >= 30 and imc <= 39.9:\n",
    "        return \"OBESIDADE\"\n",
    "    if imc >= 40:\n",
    "        return \"OBESIDADE GRAVE\"\n",
    "\n",
    "# teste unitário das funções, teste em cadeia, primeiro calculando o IMC e posteriormente classificando\n",
    "print(classificacao_imc(calcular_imc(\"92, 1.99\")))\n"
   ],
   "id": "528549c516fda49f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice de massa corporal para medir gordura do corpo.\n",
      "NORMAL\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# testando o agente criado",
   "id": "146e0717c9e0cb39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:18:42.811921Z",
     "start_time": "2025-03-10T18:18:41.115469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# testando o agente e o prompt do sistema criado\n",
    "# instanciação de teste do agente\n",
    "\n",
    "agente_imc_teste = Agente(cliente=cliente, prompt_inicial=prompt_inicial)\n",
    "\n",
    "# testando o estado inicial do agente\n",
    "resposta_do_agente = agente_imc_teste.execute()\n",
    "print(resposta_do_agente)\n",
    "\n",
    "\n",
    "resposta_do_agente = agente_imc_teste(\"Me chamo paulo, meu peso é 85 kilos e minha altura é 1,70 metros\")\n",
    "print(resposta_do_agente)"
   ],
   "id": "d5b5aca746290bdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pensamento: Qual é o seu peso e altura?\n",
      "Olá Paulo!\n",
      "\n",
      "<Pensamento>: Para calcular o IMC, preciso do peso e altura. Você me forneceu essas informações, então posso calcular o IMC.\n",
      "\n",
      "<Ação>: calcular_imc: 85, 1.70\n",
      "<Pausa>\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criando a interação do usuário e a iteração do agente",
   "id": "b0e389cf095922fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:22:09.170011Z",
     "start_time": "2025-03-10T18:22:06.519976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# executando o agente\n",
    "\n",
    "# definindo as ferramentas\n",
    "ferramentas = [\"calcular_imc\", \"classificacao_imc\"]\n",
    "\n",
    "\n",
    "# definindo o laço de repetição do agente\n",
    "def iteracao(repeticao = 10, prompt: str = \"\", verbose: bool = False):\n",
    "    '''\n",
    "    função responsavel por realizar a iteração com o agente desenvolvido\n",
    "    a função recebe um prompt incial e recebe um parametro de verbose, utilizado para imprimir os logs da solução\n",
    "    A função é executada até que o processo finalize através do ponto de parada, que é a geração da resposta esperada ou a quantidade máxima de iterações.\n",
    "    O prompt inicial é armazenado em uma lista, que simula uma memória do agente. Os próximos prompts e resultados também são armazenados.\n",
    "    Através do promtp, o agente também consegue executar ferramentas personalizadas e incluir essas repostas em prompts futuros\n",
    "    :param repeticao:\n",
    "    :param prompt:\n",
    "    :param verbose:\n",
    "    :return:\n",
    "    '''\n",
    "    agente = Agente(cliente=cliente, prompt_inicial=prompt_inicial)\n",
    "    proximo_prompt = prompt\n",
    "\n",
    "    indice = 0\n",
    "\n",
    "    # condição de parada por exaustão\n",
    "    while indice < repeticao:\n",
    "        indice += 1\n",
    "        resposta = agente(proximo_prompt)\n",
    "        if verbose: print(resposta)\n",
    "\n",
    "        if \"<Pausa>\" in resposta and \"<Ação>\" in resposta:\n",
    "            action = re.findall(r\"<Ação>: ([a-z_]+): (.+)\", resposta, re.IGNORECASE)\n",
    "            if verbose: print(action)\n",
    "            ferramenta = action[0][0]\n",
    "            if verbose: print(ferramenta)\n",
    "            parametros = action[0][1]\n",
    "            if verbose: print(parametros)\n",
    "\n",
    "\n",
    "            if ferramenta in ferramentas:\n",
    "                resultado_ferramenta = eval(f\"{ferramenta}('{parametros}')\")\n",
    "                proximo_prompt = f\"<Observação>: {resultado_ferramenta}\"\n",
    "            else:\n",
    "                proximo_prompt = \"<Observação>: Ferramenta não existente\"\n",
    "\n",
    "            if verbose: print(proximo_prompt)\n",
    "            continue\n",
    "\n",
    "        # condição de parada por chegar na resposta esperada\n",
    "        if \"<Resposta>\" in resposta:\n",
    "            print(resposta)\n",
    "            break\n",
    "\n",
    "# executando o agente\n",
    "iteracao(prompt=\"Me chamo Paulo, meu peso é 81 kilos e minha altura é 1,99 metros. Qual meu IMC?\", verbose=False)"
   ],
   "id": "3c2b7d74406167fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Resposta>: O IMC do seu peso e altura está classificado como NORMAL, parabéns! Você está dentro do peso saudável.\n",
      "\n",
      "<Dica>: Continue a se alimentar bem e a se exercitar regularmente para manter sua saúde em dia!\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
