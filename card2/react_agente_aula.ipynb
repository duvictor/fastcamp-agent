{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f20a1d3ef79e812",
   "metadata": {},
   "source": [
    "O Código abaixo faz parte do repositório https://github.com/alejandro-ao/agents-no-framework/tree/master.\n",
    "O Código foi criado no minicurso exibido no vídeo https://www.youtube.com/watch?v=hKVhRA9kfeM. E aborda a criação de agentes de IA com LLM sem a utilização de frameworks, ou seja, demonsta como criar um agente através de código python sem a utilização de ferramentas de automação de agentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c91db7555dd787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primeiro passo é instalar as bibliotecas necessárias durante a codificação\n",
    "# estas bibliotecas estão descritas no arquivo de requerimentos, que é um arquivo comumente utilizado na arquitetura de projetos python para armazenar bibliotecas e versões utilizadas\n",
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe41562cba97d80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T21:26:57.164746Z",
     "start_time": "2025-03-07T21:26:56.837935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cabd053d483888b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's natural language processing (NLP) landscape. Their importance can be attributed to several factors:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models enable quick processing of large volumes of text data, which is essential for applications such as text classification, language translation, and sentiment analysis. This speed is particularly critical in real-time applications, like chatbots, virtual assistants, and live language translation.\n",
      "\n",
      "2. **Real-Time Engagement**: Fast language models facilitate real-time engagement and interaction. In applications like customer service chatbots, fast models can respond quickly to user queries, providing an enhanced user experience. This leads to higher customer satisfaction and improved overall engagement.\n",
      "\n",
      "3. **Scalability**: As the volume of text data continues to grow, fast language models can handle this increased load without significant performance degradation. This scalability is vital for large-scale NLP applications, such as text summarization, entity recognition, and topic modeling.\n",
      "\n",
      "4. **Low Latency**: Fast language models minimize latency, which is the delay between sending a request and receiving a response. In applications like voice assistants, low latency is essential to maintain a seamless conversation flow. This ensures that users can interact with the system without experiencing frustrating delays.\n",
      "\n",
      "5. **Improved User Experience**: Fast language models contribute to an improved user experience by providing rapid and accurate responses. This is particularly important in applications where users expect fast and accurate results, such as language translation, question answering, and text summarization.\n",
      "\n",
      "6. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive advantage by offering more responsive and efficient NLP-based services. This can lead to increased market share, customer loyalty, and revenue growth.\n",
      "\n",
      "7. **Energy Efficiency**: Fast language models can be more energy-efficient, as they require less computational power to achieve the same tasks. This is particularly important in edge computing and mobile devices, where power consumption is a significant concern.\n",
      "\n",
      "8. **Enhanced Multitasking**: Fast language models enable systems to handle multiple tasks simultaneously, which is essential for applications that require multitasking, such as virtual assistants and dialogue systems.\n",
      "\n",
      "To achieve fast language models, several techniques are employed, including:\n",
      "\n",
      "1. **Model pruning**: Removing redundant or unnecessary model components to reduce computational overhead.\n",
      "2. **Knowledge distillation**: Transferring knowledge from a large model to a smaller, faster model.\n",
      "3. **Quantization**: Representing model weights and activations using lower-precision data types to reduce computation.\n",
      "4. **Efficient architectures**: Designing models with efficient architectures, such as transformers, that can be parallelized and accelerated using specialized hardware.\n",
      "\n",
      "In summary, fast language models are essential for a wide range of NLP applications, as they enable efficient processing, real-time engagement, scalability, low latency, and improved user experience. Their importance will continue to grow as the demand for responsive and accurate NLP-based services increases.\n"
     ]
    }
   ],
   "source": [
    "# Na primeira tentativa de rodar deu falha em uma biblioteca que precise fazer o donwgrade, a biblioteca foi declarada no arquivo de requirements\n",
    "# esta função instancia o cliente de llm da plataforma GROQ e executa um teste, pedindo para o modelo llama, versão 3.3 de 70 bilhões de parâmetros para que explique a importância de LLM\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715a0a17ea84e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui é gerado a arquitetura do agente.\n",
    "# primeiro o método construtor recebe o client, neste caso o modelo de LLM ou o provedor de LLM\n",
    "# ainda no construtor, é recebido como parâmetro o prompt inicial do agente\n",
    "# esta função da arquitetura do agente não retorna nenhum valor específico, porém há duas funções: call e execute que retornam os devidos valores\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde65a13e81e9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui está o prompt arquitetado para trabalhar no agente.\n",
    "# a lógica do prompt segue um fluxo iterativo com pontos de parada, iniciando pelo estado de pensamento, ação, pausa e observação\n",
    "# prompt tbm faz menção a funções em python que são executadas como ferramentas para o agente\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "\n",
    "# função responsável por chamar uma operação e executá-la\n",
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "# função responsável por retornar a massa de uma planeta do sistema solar\n",
    "def get_planet_mass(planet) -> float:\n",
    "    match planet.lower():\n",
    "        case \"earth\":\n",
    "            return 5.972e24\n",
    "        case \"jupiter\":\n",
    "            return 1.898e27\n",
    "        case \"mars\":\n",
    "            return 6.39e23\n",
    "        case \"mercury\":\n",
    "            return 3.285e23\n",
    "        case \"neptune\":\n",
    "            return 1.024e26\n",
    "        case \"saturn\":\n",
    "            return 5.683e26\n",
    "        case \"uranus\":\n",
    "            return 8.681e25\n",
    "        case \"venus\":\n",
    "            return 4.867e24\n",
    "        case _:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8c3a8a90bd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciação de teste do agente\n",
    "neil_tyson = Agent(client=client, system=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ee2513-fb55-413f-9939-c651e4d2693b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm ready to run the loop. What is the question?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testando o estado inicial do agente\n",
    "neil_tyson.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72601b194d6373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of Earth and the mass of Saturn.\n",
      "Action: get_planet_mass: Earth\n",
      "PAUSE\n",
      "Observation: 5.972e+24\n",
      "Thought: I have the mass of Earth, now I need to find the mass of Saturn.\n",
      "Action: get_planet_mass: Saturn\n",
      "PAUSE\n",
      "Observation: 5.683e+26\n",
      "Thought: I have the mass of Earth and Saturn, now I need to add them together.\n",
      "Action: calculate: 5.972e24 + 5.683e26\n",
      "PAUSE\n",
      "Observation: 5.74272e+26\n",
      "Thought: I have the sum of the masses of Earth and Saturn, now I need to multiply it by 2.\n",
      "Action: calculate: 5.74272e26 * 2\n",
      "PAUSE\n",
      "Observation: 1.148544e+27\n",
      "Answer: The mass of Earth plus the mass of Saturn and all of that times 2 is 1.148544e+27.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# definição do loop de iterações do agente\n",
    "\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "\n",
    "    # instanciação e parametrização do primeiro agente\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "\n",
    "    # ferramentas a serem utilizadas pelos agentes\n",
    "    tools = [\"calculate\", \"get_planet_mass\"]\n",
    "\n",
    "    \n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result:\n",
    "            break\n",
    "\n",
    "\n",
    "loop(query=\"What is the mass of Earth plus the mass of Saturn and all of that times 2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7cf70f55747d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
